{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Lane Lines on the Road** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cells below to import some packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def filter_color(img, masks):\n",
    "    if len(masks) == 0:\n",
    "        return\n",
    "    \n",
    "    combined_mask = masks[0]\n",
    "    for i in range(1, len(masks)):\n",
    "        combined_mask = cv2.bitwise_or(combined_mask, masks[i])\n",
    "    return cv2.bitwise_and(img, img, mask=combined_mask)\n",
    "\n",
    "def yellow_mask(img):\n",
    "    return cv2.inRange(img, np.array([65, 80, 80], np.uint8), np.array([105, 255, 255], np.uint8))\n",
    "    #return cv2.inRange(img, np.array([65, 180, 180], np.uint8), np.array([105, 255, 255], np.uint8))\n",
    "\n",
    "def white_mask(img):\n",
    "    return cv2.inRange(img, np.array([0, 0, 205], np.uint8), np.array([255, 100, 255], np.uint8))\n",
    "    \n",
    "def hsv(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def line_eqX(X, line):\n",
    "    (x1, y1, x2, y2) = line\n",
    "    m = (y2 - y1) / (x2 - x1)\n",
    "    return m * (X - x1) + y1\n",
    "\n",
    "def line_eqY(Y, line):\n",
    "    (x1, y1, x2, y2) = line\n",
    "    m = (y2 - y1) / (x2 - x1)\n",
    "    return (Y - y1) / m + x1\n",
    "\n",
    "def extend_line(line, imshape):\n",
    "    return np.array([-1, line_eqX(-1, line), imshape[1] + 5, line_eqX(imshape[1] + 5, line)], dtype=np.int32)\n",
    "\n",
    "def avg_line(lines):\n",
    "    x1 = int(sum(line[0] for line in lines)/len(lines))\n",
    "    y1 = int(sum(line[1] for line in lines)/len(lines))\n",
    "    x2 = int(sum(line[2] for line in lines)/len(lines))\n",
    "    y2 = int(sum(line[3] for line in lines)/len(lines))\n",
    "    return (x1, y1, x2, y2)\n",
    "    \n",
    "def combine_lines(line1, line2, coeff):\n",
    "    (x1, y1, x2, y2) = line1\n",
    "    (a1, b1, a2, b2) = line2\n",
    "    return (coeff * x1 + (1 - coeff) * a1,\n",
    "            coeff * y1 + (1 - coeff) * b1,\n",
    "            coeff * x2 + (1 - coeff) * a2,\n",
    "            coeff * y2 + (1 - coeff) * b2)\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        x1,y1,x2,y2 = extend_line(line, img.shape)\n",
    "        cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "def display_images(images, grayscale = False):\n",
    "    fig = plt.figure()\n",
    "    fig.set_figheight(35)\n",
    "    fig.set_figwidth(35)\n",
    "    for i in range(len(images)):\n",
    "        fig.add_subplot(len(images), 1, i + 1)\n",
    "        if grayscale:\n",
    "            plt.imshow(images[i], cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# main code\n",
    "class VideoLaneFinder:\n",
    "    def __init__(self):\n",
    "        self.init_values()\n",
    "        self.frame_lane_finder = ImageLaneFinder()\n",
    "\n",
    "    def init_values(self):\n",
    "        self.prev_left = None\n",
    "        self.prev_right = None\n",
    "    \n",
    "    def determine_left(self, line, imshape, coeff = 0):\n",
    "        self.prev_left = line if not self.prev_left else combine_lines(self.prev_left, line, coeff)\n",
    "        return self.prev_left\n",
    "\n",
    "    def determine_right(self, line, imshape, coeff = 0):\n",
    "        self.prev_right = line if not self.prev_right else combine_lines(self.prev_right, line, coeff)\n",
    "        return self.prev_right\n",
    "    \n",
    "    def process_frame(self, image):\n",
    "        left_line, right_line = self.frame_lane_finder.locate_lanes(image)\n",
    "        \n",
    "        left_lane = self.determine_left(left_line, image.shape, 0.9)\n",
    "        right_lane = self.determine_right(right_line, image.shape, 0.9)\n",
    "        \n",
    "        return self.frame_lane_finder.draw_lanes(image, (left_lane, right_lane))\n",
    "        \n",
    "    def find_lanes(self, video):\n",
    "        self.init_values()\n",
    "        output_video = video.fl_image(self.process_frame)\n",
    "        return output_video\n",
    "        \n",
    "class ImageLaneFinder:\n",
    "    def locate_lanes(self, image):\n",
    "        hsv_img = hsv(image)\n",
    "        blurred = gaussian_blur(hsv_img, 5)\n",
    "        filtered = filter_color(blurred, [yellow_mask(blurred), white_mask(blurred)])\n",
    "        edges = canny(filtered, 75, 150)\n",
    "\n",
    "        imshape = image.shape\n",
    "        vertices = np.array([[(0,imshape[0]),(imshape[1]/2.1, imshape[0]/1.65), (imshape[1]*2/3.7, imshape[0]/1.65), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "        masked = region_of_interest(edges, vertices)\n",
    "\n",
    "        lines = cv2.HoughLinesP(masked, 1, np.pi/90, 5, np.array([]), minLineLength=50, maxLineGap=150)\n",
    "\n",
    "        left_lines, right_lines = self.divide_lines(lines, imshape)\n",
    "        return avg_line(left_lines), avg_line(right_lines)\n",
    "    \n",
    "    def draw_lanes(self, image, lanes):\n",
    "        imshape = image.shape\n",
    "        black_image = np.zeros((imshape[0],imshape[1],3), np.uint8)\n",
    "        draw_lines(black_image, lanes, color=[255, 0, 0], thickness=10)\n",
    "        \n",
    "        vertices = np.array([[(0,imshape[0]),(imshape[1]/2.15, imshape[0]/1.65), (imshape[1]*2/3.65, imshape[0]/1.65), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "        new_masked = region_of_interest(black_image, vertices)\n",
    "        \n",
    "        return weighted_img(new_masked, image, α=0.8, β=0.6, λ=0.5)\n",
    "    \n",
    "    def find_lanes(self, image):\n",
    "        return self.draw_lanes(image, self.locate_lanes(image))\n",
    "    \n",
    "    def divide_lines(self, lines, imshape):\n",
    "        left_lane = []\n",
    "        right_lane = []\n",
    "        for line in lines:\n",
    "            #((y2-y1)/(x2-x1))\n",
    "            x1,y1,x2,y2 = line[0]\n",
    "            slope = ((y2-y1)/(x2-x1))\n",
    "            if slope > 0.4 and slope < 1 and x1 > imshape[1]/2.0:\n",
    "                left_lane.append(line[0])\n",
    "            elif slope < -0.4 and slope > -1 and x1 < imshape[1]/2.0:\n",
    "                right_lane.append(line[0])\n",
    "        return (left_lane, right_lane)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running our solution on all test_images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-3d6074cb7b19>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-3d6074cb7b19>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    display_images([gray_images, grayscale=True)\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "all_image_names = os.listdir(\"test_images/\")\n",
    "all_images = [np.copy(mpimg.imread(\"test_images/\" + image_name)) for image_name in all_image_names]\n",
    "image_lane_finder = ImageLaneFinder()\n",
    "gray_images = [image_lane_finder.find_lanes(image) for image in all_images]\n",
    "display_images([gray_images, grayscale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_lane_finder = VideoLaneFinder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the one with the solid white lane on the right first ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = video_lane_finder.find_lanes(clip1)\n",
    "white_clip.write_videofile(white_output, audio=False)\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the one with the solid yellow lane on the left. This one's more tricky!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yellow_output = 'yellow.mp4'\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "yellow_clip = video_lane_finder.find_lanes(clip2)\n",
    "yellow_clip.write_videofile(yellow_output, audio=False)\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections\n",
    "\n",
    "The biggest problem seems to be the parameter tweaking. I can tweak hough lines params to work very well for one video, but it might fail for the other. I can tweak yellow and white color ranges for color filtering, but that will certainly fail under some other lighting conditions. \n",
    "\n",
    "There is just a lot of variables that need to be tweaked for different road and lighting conditions, so this kind of approach doesn't seem to generalize well. I am absolutely not confident that this would work on a random new video.\n",
    "\n",
    "A reasonable approach would be to do some sort of parameter exploration, starting off with very conservative parameters, and, if failing to find a lane, loosening up the parameters, but this doesn't seem very performant.\n",
    "\n",
    "Another possiblity is figuring out if it's possible to calibrate the params at the beginning of the video, but this might again fail in changing conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optional Challenge\n",
    "\n",
    "The following video is more challenging than the previous two because:\n",
    "  1. the top of the car is visible at the bottom of the video\n",
    "  2. The road has been repaired, resulting in a sharp change of road color in two places, for which the gradient will be high\n",
    "  3. There are shadows from trees that result in many noise lines\n",
    "  4. The light section of the repaired road has a horrible contrast compared to the yellow lane line, which required some special tweaking.\n",
    "  \n",
    "What helped to make this video work is to pre-filter the images with yellow and white filters. This got rid of the road repair transition line. Additionally, we also do a weighted sum of the lane line from the previous frame and a current frame, to help with jitters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "challenge_output = 'extra.mp4'\n",
    "clip2 = VideoFileClip('challenge.mp4')\n",
    "challenge_clip = video_lane_finder.find_lanes(clip2)\n",
    "challenge_clip.write_videofile(challenge_output, audio=False)\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
